{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgzEvubZQ9sG9D7NFg12s3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somaharshithareddy/Books-Python/blob/main/internals_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11111\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "data = pd.read_csv('/content/Housing.csv')\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "print(\"\\nChecking for null values:\")\n",
        "print(data.isnull().sum())\n",
        "non_numeric_columns = data.select_dtypes(exclude=['number']).columns.tolist()\n",
        "data = pd.get_dummies(data, columns=non_numeric_columns)\n",
        "sns.pairplot(data)\n",
        "plt.show()\n",
        "cov_matrix = data.cov()\n",
        "corr_matrix = data.corr()\n",
        "print(\"\\nCovariance matrix:\\n\")\n",
        "print(cov_matrix)\n",
        "print(\"\\nCorrelation matrix:\\n\")\n",
        "print(corr_matrix)\n",
        "X = data.drop('area', axis=1)\n",
        "y = data['area']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = r2_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy (R2 score) of the model:\", accuracy)"
      ],
      "metadata": {
        "id": "6hT9CmRYYiqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###2222222222\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "path=\"/content/Housing.csv\"\n",
        "data=pd.read_csv(path)\n",
        "print(data.head())\n",
        "count=data.info()\n",
        "print(count)\n",
        "print(data.isnull().sum())\n",
        "data.plot()\n",
        "plt.show()\n",
        "cov_mat=data.cov(numeric_only=True)\n",
        "corr_mat=data.corr(numeric_only=True)\n",
        "print(\"covarience matrix:\")\n",
        "print(cov_mat)\n",
        "print(\"correlation matrix:\")\n",
        "print(corr_mat)\n",
        "non_numeric_columns = data.select_dtypes(exclude=['number']).columns.tolist()\n",
        "data = pd.get_dummies(data, columns=non_numeric_columns)\n",
        "X=data.drop([\"area\"],axis=1)\n",
        "y=data[\"area\"]\n",
        "X_encoded = pd.get_dummies(X, columns=['price'])\n",
        "X_encoded.fillna(data[\"bedrooms\"].mean(), inplace=True)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X_encoded,y,test_size=0.09)\n",
        "\n",
        "model=SGDRegressor()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "print(y_pred)\n",
        "a=model.score(X_test,y_test)\n",
        "# a=accuracy_score(y_test,y_pred)\n",
        "print(f\"the accuracy of the model is : {a} \")\n",
        "plt.plot(y_test[1:10],y_pred[1:10])\n",
        "plt.xlabel(\"actual value\")\n",
        "plt.ylabel(\"predicted value\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oo6sUvzHYpHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###333333333\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "iris_df = pd.read_csv(\"/content/Iris.csv\")\n",
        "print(iris_df.head())\n",
        "print(iris_df.count())\n",
        "print(iris_df.isnull().any())\n",
        "print(iris_df.isnull().sum())\n",
        "iris=iris_df.drop([\"Id\"],axis=1)\n",
        "iris.plot()\n",
        "plt.show()\n",
        "cov_mat=iris.cov()\n",
        "print(cov_mat)\n",
        "corr_mat=iris.corr()\n",
        "print(corr_mat)\n",
        "X=iris.drop([\"Species\"],axis=1)\n",
        "y=iris[\"Species\"]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n",
        "model=LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "print(y_pred)\n",
        "a=model.score(X_test,y_test)\n",
        "aa=accuracy_score(y_test,y_pred)\n",
        "print(f\"the accuracy is : {a} {aa}\")\n"
      ],
      "metadata": {
        "id": "Z0hQh8yyfexA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###44444\n",
        "import csv\n",
        "def find_s(training_data):\n",
        " hypothesis=[]\n",
        " hypothesis = training_data[0][:-1]\n",
        " for example in training_data:\n",
        "  features = example[:-1]\n",
        "  label = example[-1]\n",
        "  if label == 'Yes':\n",
        "    for i in range(len(hypothesis)):\n",
        "      if hypothesis[i] != features[i]:\n",
        "        hypothesis[i] = '?'\n",
        " print(hypothesis)\n",
        " return hypothesis\n",
        "training_data = []\n",
        "with open('/content/tennis.csv', 'r') as file:\n",
        " csv_reader = csv.reader(file)\n",
        " for row in csv_reader:\n",
        "  training_data.append(row)\n",
        " print(training_data)\n",
        " training_data.pop(0)\n",
        " print(training_data)\n",
        "h = find_s(training_data)\n",
        "print(\"Most specific hypothesis:\", h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyghsQ23f6HL",
        "outputId": "95ec9cf4-e1ba-4a18-ae54-ccadd8d286ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['outlook', 'temp', 'humidity', 'windy', 'play'], ['sunny', 'hot', 'high', 'false', 'no'], ['sunny', 'hot', 'high', 'true', 'no'], ['overcast', 'hot', 'high', 'false', 'yes'], ['rainy', 'mild', 'high', 'false', 'yes'], ['rainy', 'cool', 'normal', 'false', 'yes'], ['rainy', 'cool', 'normal', 'true', 'no'], ['overcast', 'cool', 'normal', 'true', 'yes'], ['sunny', 'mild', 'high', 'false', 'no'], ['sunny', 'cool', 'normal', 'false', 'yes'], ['rainy', 'mild', 'normal', 'false', 'yes'], ['sunny', 'mild', 'normal', 'true', 'yes'], ['overcast', 'mild', 'high', 'true', 'yes'], ['overcast', 'hot', 'normal', 'false', 'yes'], ['rainy', 'mild', 'high', 'true', 'no']]\n",
            "[['sunny', 'hot', 'high', 'false', 'no'], ['sunny', 'hot', 'high', 'true', 'no'], ['overcast', 'hot', 'high', 'false', 'yes'], ['rainy', 'mild', 'high', 'false', 'yes'], ['rainy', 'cool', 'normal', 'false', 'yes'], ['rainy', 'cool', 'normal', 'true', 'no'], ['overcast', 'cool', 'normal', 'true', 'yes'], ['sunny', 'mild', 'high', 'false', 'no'], ['sunny', 'cool', 'normal', 'false', 'yes'], ['rainy', 'mild', 'normal', 'false', 'yes'], ['sunny', 'mild', 'normal', 'true', 'yes'], ['overcast', 'mild', 'high', 'true', 'yes'], ['overcast', 'hot', 'normal', 'false', 'yes'], ['rainy', 'mild', 'high', 'true', 'no']]\n",
            "['sunny', 'hot', 'high', 'false']\n",
            "Most specific hypothesis: ['sunny', 'hot', 'high', 'false']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##66666\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "path = \"/content/tennis.csv\"\n",
        "data = pd.read_csv(path)\n",
        "X = data.drop('play', axis=1)\n",
        "y = data['play']\n",
        "X_encoded = pd.get_dummies(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)\n",
        "decision_tree = DecisionTreeClassifier(criterion='entropy')\n",
        "decision_tree.fit(X_train, y_train)\n",
        "new_sample = X_test.iloc[[0]]\n",
        "predicted_class = decision_tree.predict(new_sample)\n",
        "print(\"Predicted class for the new sample:\", predicted_class[0])\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(decision_tree,feature_names=X_encoded.columns,class_names=['no','yes'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0DhWkFH3hIsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####77777\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Example data\n",
        "data = np.array([\n",
        "    [0.1, 0.6, 'ClassA'],\n",
        "    [0.15, 0.71, 'ClassA'],\n",
        "    [0.08, 0.9, 'ClassA'],\n",
        "    [0.16, 0.85, 'ClassA'],\n",
        "    [0.2, 0.3, 'ClassB'],\n",
        "    [0.25, 0.5, 'ClassB'],\n",
        "    [0.24, 0.1, 'ClassB'],\n",
        "    [0.3, 0.2, 'ClassB'],\n",
        "    [0.45, 0.6, 'ClassC'],\n",
        "    [0.5, 0.2, 'ClassC'],\n",
        "    [0.55, 0.3, 'ClassC'],\n",
        "    [0.52, 0.25, 'ClassC'],\n",
        "    [0.1, 0.4, 'Unknown']\n",
        "])\n",
        "X = data[:, :2].astype(float)\n",
        "y = data[:, 2]\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "centroid_labels = {}\n",
        "for i, label in enumerate(kmeans.labels_):\n",
        "    if label not in centroid_labels:\n",
        "        centroid_labels[label] = {}\n",
        "    if y[i] in centroid_labels[label]:\n",
        "        centroid_labels[label][y[i]] += 1\n",
        "    else:\n",
        "        centroid_labels[label][y[i]] = 1\n",
        "\n",
        "for label in centroid_labels:\n",
        "    centroid_labels[label] = max(centroid_labels[label], key=centroid_labels[label].get)\n",
        "new_data_point = np.array([0.906, 0.606]).reshape(1, -1)\n",
        "predicted_label = centroid_labels[kmeans.predict(new_data_point)[0]]\n",
        "\n",
        "print(f\"Predicted classification for VAR1=0.906 and VAR2=0.606 is {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "NpCpkJn4isvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###8888\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "path=\"/content/Iris.csv\"\n",
        "data=pd.read_csv(path)\n",
        "print(data.head())\n",
        "x=data[\"SepalLengthCm\"]\n",
        "y=data[\"Species\"]\n",
        "plt.xlabel(\"sepal length\")\n",
        "plt.ylabel(\"species\")\n",
        "plt.plot(x,y)\n",
        "plt.show()\n",
        "X=data.drop([\"Species\"],axis=1)\n",
        "y=data[\"Species\"]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=15)\n",
        "model=KNeighborsClassifier()\n",
        "model.fit(X,y)\n",
        "y_pred=model.predict(X_test)\n",
        "print(y_pred)\n",
        "a=accuracy_score(y_test,y_pred)\n",
        "print(f\"the accuracy is : {a}\")\n"
      ],
      "metadata": {
        "id": "r_8STMb5o3wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###99999\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "california_housing = fetch_california_housing()\n",
        "data = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "target = pd.DataFrame(california_housing.target, columns=['target'])\n",
        "df = pd.concat([data, target], axis=1)\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nChecking for null values in the dataset:\")\n",
        "print(df.isnull().sum())\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.hist(df['MedInc'], bins=30, color='skyblue')\n",
        "plt.title('Median Income')\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.hist(df['HouseAge'], bins=30, color='salmon')\n",
        "plt.title('House Age')\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist(df['AveRooms'], bins=30, color='green')\n",
        "plt.title('Average Rooms')\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.hist(df['AveOccup'], bins=30, color='orange')\n",
        "plt.title('Average Occupancy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "correlation_matrix = df.corr()\n",
        "covariance_matrix = df.cov()\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "print(\"\\nCovariance Matrix:\")\n",
        "print(covariance_matrix)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "sgd_regressor = SGDRegressor(max_iter=1000, tol=1e-3, random_state=42)\n",
        "sgd_regressor.fit(X_train, y_train)\n",
        "predictions = sgd_regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(\"\\nMetrics for the Gradient Descent Regressor:\")\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared Score:\", r2)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nha11d19tSka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###10000\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def kernel(point, xmat, k):\n",
        "    m, n = np.shape(xmat)\n",
        "    weights = np.mat(np.eye(m))\n",
        "    for j in range(m):\n",
        "        diff = point - xmat[j]\n",
        "        weights[j, j] = np.exp(diff * diff.T / (-2.0 * k**2))\n",
        "    return weights\n",
        "\n",
        "def localWeight(point, xmat, ymat, k):\n",
        "    wei = kernel(point, xmat, k)\n",
        "    W = (xmat.T * (wei * xmat)).I * (xmat.T * (wei * ymat.T))\n",
        "    return W\n",
        "\n",
        "def localWeightRegression(xmat, ymat, k):\n",
        "    m, n = np.shape(xmat)\n",
        "    ypred = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        ypred[i] = xmat[i] * localWeight(xmat[i], xmat, ymat, k)\n",
        "    return ypred\n",
        "data = pd.read_csv('/content/10-dataset.csv')\n",
        "bill, tip = np.array(data.total_bill), np.array(data.tip)\n",
        "X = np.hstack((np.ones((len(bill), 1)), np.mat(bill).T))\n",
        "ypred = localWeightRegression(X, np.mat(tip), 0.5)\n",
        "sorted_indices = bill.argsort()\n",
        "sorted_bill, sorted_tip = bill[sorted_indices], tip[sorted_indices]\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(bill, tip, color='green')\n",
        "ax.plot(sorted_bill, ypred[sorted_indices], color='red', linewidth=5)\n",
        "plt.xlabel('Total bill')\n",
        "plt.ylabel('Tip')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5spRyNcJyAJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}